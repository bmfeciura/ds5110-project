{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 5110 Group Project\n",
    "Team: Alexandra Cathcart (adc6fs), Benjamin Feciura (bmf3bw), Jeremey Donovan (jdd5dw), Jordan Hiatt (jdh2e)\n",
    "\n",
    "Original data: https://www.kaggle.com/reddit/reddit-comments-may-2015\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Includes & Spark Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import *\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, countDistinct, lower, size, split, udf, when\n",
    "from pyspark.sql.types import ArrayType, IntegerType,  StringType, StructType\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the reddit data\n",
    "full_path = '/project/ds5559/r-slash-group8/sample.csv'\n",
    "\n",
    "df = spark.read.csv(full_path,  inferSchema=True, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Bad Word data\n",
    "schema = StructType().add(\"badWord\",StringType(),True)\n",
    "dfBW=spark.read.format(\"csv\").schema(schema).load('bad_words.csv')\n",
    "#  dfBW.show(5)  # not showing since words are quite vulgar\n",
    "\n",
    "# Also create in list format\n",
    "listBW=list(dfBW.select('badWord').toPandas()['badWord']) \n",
    "# listBW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regex with all the bad words\n",
    "# if there is an issue, try \\\\\\\\b instead\n",
    "listBW=list(map(lambda line: \"\\\\b\" + line + \"\\\\b\",listBW))\n",
    "delim='|'\n",
    "strBW=delim.join(listBW)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ups: integer (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- removal_reason: string (nullable = true)\n",
      " |-- downs: integer (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- distinguished: string (nullable = true)\n",
      "\n",
      "+----+---------+--------------+-----+------------+--------------------+-------------+\n",
      "| ups|subreddit|removal_reason|downs|      author|                body|distinguished|\n",
      "+----+---------+--------------+-----+------------+--------------------+-------------+\n",
      "|   4|soccer_jp|            NA|    0|       rx109|                くそ|         null|\n",
      "|null|     null|          null| null|        null|                null|         null|\n",
      "|   0|     null|          null| null|        null|                null|         null|\n",
      "|   4|      nba|            NA|    0|   WyaOfWade|gg this one's ove...|           NA|\n",
      "|   0| politics|            NA|    0|Wicked_Truth|Are you really im...|           NA|\n",
      "+----+---------+--------------+-----+------------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop unneeded cols from dataframe\n",
    "df=df.drop('_c0','created_utc','subreddit_id','link_id','name','score_hidden','author_flair_css_class', 'gilded', \\\n",
    "        'author_flair_text','id','archived','retrieved_on', 'edited','controversiality','parent_id','score')\n",
    "\n",
    "# convert integer cols (ups, downs, and gilded) to integers\n",
    "# Note: we could have done this by defining a schema before the csv read\n",
    "df=df.withColumn(\"ups\",df.ups.cast(IntegerType()))\n",
    "df=df.withColumn(\"downs\",df.downs.cast(IntegerType()))\n",
    "#df=df.withColumn(\"gilded\",df.gilded.cast(IntegerType()))  # Removed gilded since not used in this analysis\n",
    "\n",
    "# Confirm new schema\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15317725"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of rows before removing NA\n",
    "df.count()\n",
    "# There are 15,317,725 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------+-----+--------------+--------------------+-------------+\n",
      "|ups|subreddit|removal_reason|downs|        author|                body|distinguished|\n",
      "+---+---------+--------------+-----+--------------+--------------------+-------------+\n",
      "|  4|soccer_jp|            NA|    0|         rx109|                くそ|         null|\n",
      "|  4|      nba|            NA|    0|     WyaOfWade|gg this one's ove...|           NA|\n",
      "|  0| politics|            NA|    0|  Wicked_Truth|Are you really im...|           NA|\n",
      "|  3|AskReddit|            NA|    0|      jesse9o3|No one has a Euro...|           NA|\n",
      "|  3|AskReddit|            NA|    0|beltfedshooter|\"That the kid \"\"....|           NA|\n",
      "+---+---------+--------------+-----+--------------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove rows where up, down, or body is null. We  do this since inference of these values is not applicable\n",
    "df=df.filter(df['ups'].isNotNull())\n",
    "df=df.filter(df['downs'].isNotNull())\n",
    "df=df.filter(df['body'].isNotNull())\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where the author was '[deleted]' \n",
    "df=df.filter(df['author']!='[deleted]')\n",
    "\n",
    "# Remove author \"0\"\n",
    "df=df.filter(df['author']!='0')\n",
    "\n",
    "\n",
    "# Remove rows where the author was 'AutoModerator'\n",
    "# see https://www.reddit.com/wiki/automoderator\n",
    "df=df.filter(df['author']!='AutoModerator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9226090"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of rows AFTER removing NA\n",
    "df.count()\n",
    "# There now 9,229,025 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all body text\n",
    "df=df.withColumn('body',lower(col('body')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------+-----+--------------+--------------------+-------------+-----+\n",
      "|ups|subreddit|removal_reason|downs|        author|                body|distinguished|score|\n",
      "+---+---------+--------------+-----+--------------+--------------------+-------------+-----+\n",
      "|  4|soccer_jp|            NA|    0|         rx109|                くそ|         null|    4|\n",
      "|  4|      nba|            NA|    0|     WyaOfWade|gg this one's ove...|           NA|    4|\n",
      "|  0| politics|            NA|    0|  Wicked_Truth|are you really im...|           NA|    0|\n",
      "|  3|AskReddit|            NA|    0|      jesse9o3|no one has a euro...|           NA|    3|\n",
      "|  3|AskReddit|            NA|    0|beltfedshooter|\"that the kid \"\"....|           NA|    3|\n",
      "+---+---------+--------------+-----+--------------+--------------------+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Even though we dropped the column, adding score back into dataframe by computing it\n",
    "df=df.withColumn('score',df['ups']-df['downs'])\n",
    "df=df.withColumn(\"score\",df.score.cast(IntegerType()))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------+-----+---------+--------------------+-------------+-----+--------------+\n",
      "|ups|subreddit|removal_reason|downs|   author|                body|distinguished|score|scoreSentiment|\n",
      "+---+---------+--------------+-----+---------+--------------------+-------------+-----+--------------+\n",
      "|  4|soccer_jp|            NA|    0|    rx109|                くそ|         null|    4|           2.0|\n",
      "|  4|      nba|            NA|    0|WyaOfWade|gg this one's ove...|           NA|    4|           2.0|\n",
      "+---+---------+--------------+-----+---------+--------------------+-------------+-----+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Determine a scoreSentiment as either postive, neutral, or negative.\n",
    "# This will be our response variable\n",
    "\n",
    "# Drop scoreSentiment if it already exists\n",
    "df=df.drop('scoreSentiment')\n",
    "\n",
    "# Set up bucketizer\n",
    "splits = [-float(\"inf\"), -0.1,0.1, float(\"inf\")]\n",
    "bkt = Bucketizer(splits=splits, inputCol=\"score\", outputCol=\"scoreSentiment\")\n",
    "\n",
    "# Transform to add scoreSentiment: 0=negative; 1=neutral; 2=positive.\n",
    "df=bkt.transform(df)\n",
    "\n",
    "# !!! Cannot shift to -1,0,1 since LR must start with 0 !!!\n",
    "# To make things more clear, shift to -1=negative; 0=neutral; 1=positive\n",
    "#df=df.withColumn(\"scoreSentiment\", \\\n",
    "#                 when(df['scoreSentiment']==0,-1) \\\n",
    "#                 .when(df['scoreSentiment']==1,0) \\\n",
    "#                 .otherwise(1)\n",
    "#                ) \n",
    "\n",
    "df.show(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag comments containing bad words\n",
    "df=df.withColumn('bwFlag',col('body').rlike(strBW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append bodyWordCount\n",
    "df=df.withColumn(\"bodyWordCount\", size(split(df['body'], ' ')))\n",
    "#df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting & Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=314\n",
    "trainDF,testDF,holdoutDF=df.randomSplit([0.4,0.4,0.2],seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-56-198fda75c5b9>\", line 4, in <module>\n",
      "    df.groupby('bwFlag').agg({\"bwFlag\":\"count\"}).show()\n",
      "  File \"/usr/local/spark/python/pyspark/sql/dataframe.py\", line 440, in show\n",
      "    print(self._jdf.showString(n, 20, vertical))\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1303, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1033, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1200, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/opt/conda/lib/python3.7/socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '<ipython-input-56-198fda75c5b9>'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/opt/conda/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-198fda75c5b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# NOTE: This has a rather long runtime!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bwFlag'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"bwFlag\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"count\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#df.filter(df['bwFlag']==True).show(5,False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2060\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2064\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# How many comments have bad words?\n",
    "# Confirm the flagging worked by looking at how many comments contain bad words vs good\n",
    "# NOTE: This has a rather long runtime!!!\n",
    "df.groupby('bwFlag').agg({\"bwFlag\":\"count\"}).show()\n",
    "#df.filter(df['bwFlag']==True).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many authors are there?\n",
    "df.select(countDistinct('author')).show()\n",
    "# There are 1,234,824 authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the top 10 authors with sum of ups and downs\n",
    "df.groupby('author').agg({\"author\":\"count\",\"ups\":\"sum\",\"downs\":\"sum\",\"score\":\"sum\"}).sort(col('count(author)').desc()).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Odd that the preceding authors have no down but this is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show authors with the lowest scores\n",
    "df.groupby('author').agg({\"score\":\"sum\",\"ups\":\"sum\",\"downs\":\"sum\"}).sort(col('sum(score)').asc()).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a summary of score sentiment by label\n",
    "#tmpDF.groupby('scoreSentiment').agg({\"scoreSentiment\":\"count\"}).show()\n",
    "df.groupby('scoreSentiment').agg({\"scoreSentiment\":\"count\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graphical Distribution of sentiment (TBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Predict Sentiment from body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'filter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-38b319ec32e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Though not the cleanest thing to do from a data sci perspective, we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# are going to drop the neutral sentiment rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scoreSentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'filter'"
     ]
    }
   ],
   "source": [
    "# Though not the cleanest thing to do from a data sci perspective, we\n",
    "# are going to drop the neutral sentiment rows\n",
    "df=df.filter(df['scoreSentiment']!=1)\n",
    "# Shift positive from 2 to 1\n",
    "df=df.withColumn(\"scoreSentiment\", \\\n",
    "                 when(df['scoreSentiment']==2,1) \\\n",
    "                 .when(df['scoreSentiment']==0,0) \\\n",
    "                 .otherwise(-1)\n",
    "                ) \n",
    "# we should never have the otherwise case!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               words|                  tf|\n",
      "+--------------------+--------------------+\n",
      "|              [くそ]|   (200,[147],[1.0])|\n",
      "|[gg, this, one's,...|(200,[2,17,24,35,...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create TF (Term Frequency) feature\n",
    "tok = Tokenizer(inputCol=\"body\", outputCol=\"words\")\n",
    "htf = HashingTF(inputCol=\"words\", outputCol=\"tf\", numFeatures=200)  \n",
    "\n",
    "#testing\n",
    "tmpDF=tok.transform(df)\n",
    "tmpDF=htf.transform(tmpDF)\n",
    "tmpDF.select('words','tf').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------+-----+---------+--------------------+-------------+-----+--------------+------+-------------+--------------------+--------------------+\n",
      "|ups|subreddit|removal_reason|downs|   author|                body|distinguished|score|scoreSentiment|bwFlag|bodyWordCount|             bodyVec|                 w2v|\n",
      "+---+---------+--------------+-----+---------+--------------------+-------------+-----+--------------+------+-------------+--------------------+--------------------+\n",
      "|  4|soccer_jp|            NA|    0|    rx109|                くそ|         null|    4|             1| false|            1|              [くそ]|[0.0,0.0,0.0,0.0,...|\n",
      "|  4|      nba|            NA|    0|WyaOfWade|gg this one's ove...|           NA|    4|             1| false|           12|[gg this one's ov...|[0.0,0.0,0.0,0.0,...|\n",
      "+---+---------+--------------+-----+---------+--------------------+-------------+-----+--------------+------+-------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create w2v (word to vec) feature\n",
    "\n",
    "# the comment string needs to be turned into a vector for w2v to work\n",
    "# unfortunately, VectorAssember does not work on string so we need a UDF\n",
    "\n",
    "# Create UDF (note: split(anything,0) simply means don't split)\n",
    "str_to_vec=spark.udf.register(\"str_to_vec\",\n",
    "                             lambda row:row.split(\"#\",0),\n",
    "                             ArrayType(StringType()))\n",
    "\n",
    "# set up the tranformation\n",
    "rva=SQLTransformer(statement=\"SELECT *, str_to_vec(body) bodyVec FROM __THIS__\")\n",
    "\n",
    "w2v = Word2Vec(inputCol='bodyVec', outputCol='w2v')  # not setting minCount \n",
    "\n",
    "# testing\n",
    "tmpDF=rva.transform(df)\n",
    "model=w2v.fit(tmpDF)\n",
    "tmpDF=model.transform(tmpDF)\n",
    "tmpDF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble predictors\n",
    "va=VectorAssembler(inputCols=['tf','w2v','bwFlag','bodyWordCount'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the regression model\n",
    "lr = LogisticRegression(labelCol='scoreSentiment',maxIter=10, regParam=0.3, elasticNetParam=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the pipeline\n",
    "#pipeline=Pipeline(stages=[bkt,tok,htf,rva,w2v,va,lr])  # took out bkt since this is pre-EDA\n",
    "pipeline=Pipeline(stages=[tok,htf,rva,w2v,va,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o474.fit.\n: org.apache.spark.SparkException: Classification labels should be in [0 to 1]. Found 157931 invalid labels.\n\tat org.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:556)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:487)\n\tat org.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:482)\n\tat org.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:281)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:150)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-6737343558e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit the multinomial logistic regression model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmlrModel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \"\"\"\n\u001b[1;32m    317\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o474.fit.\n: org.apache.spark.SparkException: Classification labels should be in [0 to 1]. Found 157931 invalid labels.\n\tat org.apache.spark.ml.classification.LogisticRegression.$anonfun$train$1(LogisticRegression.scala:556)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:487)\n\tat org.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:482)\n\tat org.apache.spark.ml.classification.LogisticRegression.train(LogisticRegression.scala:281)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:150)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "# Fit the multinomial logistic regression model\n",
    "mlrModel=pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      "3 X 300 CSRMatrix\n",
      "\n",
      "Intercept: [-1.0264586714522934,-1.0107704204551655,2.037229091907459]\n",
      "objectiveHistory:\n",
      "0.35298803317465105\n",
      "False positive rate by label:\n",
      "label 0: 0.0\n",
      "label 1: 0.0\n",
      "label 2: 1.0\n",
      "True positive rate by label:\n",
      "label 0: 0.0\n",
      "label 1: 0.0\n",
      "label 2: 1.0\n",
      "Precision by label:\n",
      "label 0: 0.0\n",
      "label 1: 0.0\n",
      "label 2: 0.9139359489937812\n",
      "Recall by label:\n",
      "label 0: 0.0\n",
      "label 1: 0.0\n",
      "label 2: 1.0\n",
      "F-measure by label:\n",
      "label 0: 0.0\n",
      "label 1: 0.0\n",
      "label 2: 0.9550329513109017\n",
      "Accuracy: 0.9139359489937812\n",
      "FPR: 0.9139359489937812\n",
      "TPR: 0.9139359489937812\n",
      "F-measure: 0.8728389466766606\n",
      "Precision: 0.8352789188631633\n",
      "Recall: 0.9139359489937812\n"
     ]
    }
   ],
   "source": [
    "# Training Summary\n",
    "# source: https://spark.apache.org/docs/latest/ml-classification-regression.html\n",
    "\n",
    "# Fix source: https://stackoverflow.com/questions/37278999/logistic-regression-with-spark-ml-data-frames\n",
    "lrm=mlrModel.stages[-1]\n",
    "\n",
    "# Print the coefficients and intercept for multinomial logistic regression\n",
    "print(\"Coefficients: \\n\" + str(lrm.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(lrm.interceptVector))\n",
    "\n",
    "trainingSummary = lrm.summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# for multiclass, we can inspect metrics on a per-label basis\n",
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make preductions on the test data\n",
    "mlrPrediction=mlrModel.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+\n",
      "|scoreSentiment|prediction|\n",
      "+--------------+----------+\n",
      "|           0.0|       2.0|\n",
      "|           0.0|       2.0|\n",
      "|           0.0|       2.0|\n",
      "+--------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlrPrediction.select('scoreSentiment','prediction').show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TBD: Evaluate the predictions. Judging from the training though, it seems to over-predict category 2 \"positive\" --- which is the most prevalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stuff with ngrams not currently used\n",
    "\n",
    "#May need to drop col when rerunning\n",
    "#df=df.drop('body2grams')\n",
    "#df=df.drop('body3grams')\n",
    "\n",
    "# Create 2grams\n",
    "#ngram = NGram(n=2, inputCol=\"words\", outputCol=\"body2grams\")\n",
    "#df = ngram.transform(df)\n",
    "\n",
    "# Create 3grams\n",
    "#ngram = NGram(n=3, inputCol=\"words\", outputCol=\"body3grams\")\n",
    "#df = ngram.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT USED since scoreSentiment is multinomial response not predictor\n",
    "# OneHotEncoding of Score_sentiment\n",
    "# since it is already numeric, no need for StringIndexer\n",
    "#encoder = OneHotEncoder(inputCol=\"score_sentiment\", outputCol=\"scoreSentimentVec\")\n",
    "#model = encoder.fit(df)\n",
    "#df = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save notebook as PDF document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook /sfs/qumulo/qhome/jdd5dw/ds5110-project/Jeremey_code.ipynb to pdf\n",
      "[NbConvertApp] Writing 57104 bytes to notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 68569 bytes to /sfs/qumulo/qhome/jdd5dw/ds5110-project/Jeremey_code.pdf\n",
      "[NbConvertApp] Converting notebook /sfs/qumulo/qhome/jdd5dw/ds5110-project/test_file.ipynb to pdf\n",
      "[NbConvertApp] Writing 26544 bytes to notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
      "[NbConvertApp] CRITICAL | xelatex failed: ['xelatex', 'notebook.tex', '-quiet']\n",
      "This is XeTeX, Version 3.14159265-2.6-0.99999 (TeX Live 2019/dev/Debian) (preloaded format=xelatex)\n",
      " restricted \\write18 enabled.\n",
      "entering extended mode\n",
      "(./notebook.tex\n",
      "LaTeX2e <2018-12-01>\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/article.cls\n",
      "Document Class: article 2018/09/03 v1.4i Standard LaTeX document class\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/size11.clo))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/tcolorbox/tcolorbox.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/basiclayer/pgf.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/utilities/pgfrcs.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfutil-common.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfutil-common-lists.t\n",
      "ex)) (/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfutil-latex.def\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/ms/everyshi.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfrcs.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/pgf.revision.tex)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/basiclayer/pgfcore.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics/graphicx.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics/keyval.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics/graphics.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics/trig.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics-cfg/graphics.cfg)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics-def/xetex.def)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/systemlayer/pgfsys.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfkeys.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfkeysfiltered.code.t\n",
      "ex)) (/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgf.cfg)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys-xetex.def\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys-dvipdfmx.def\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys-common-pdf.de\n",
      "f))))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsyssoftpath.code.\n",
      "tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsysprotocol.code.\n",
      "tex)) (/usr/share/texlive/texmf-dist/tex/latex/xcolor/xcolor.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics-cfg/color.cfg))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcore.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmath.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathcalc.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathutil.code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathparser.code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.basic.code\n",
      ".tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.trigonomet\n",
      "ric.code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.random.cod\n",
      "e.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.comparison\n",
      ".code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.base.code.\n",
      "tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.round.code\n",
      ".tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.misc.code.\n",
      "tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.integerari\n",
      "thmetics.code.tex)))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfloat.code.tex))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepoints.code.te\n",
      "x)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathconstruct.\n",
      "code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathusage.code\n",
      ".tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorescopes.code.te\n",
      "x)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoregraphicstate.c\n",
      "ode.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoretransformation\n",
      "s.code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorequick.code.tex\n",
      ")\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreobjects.code.t\n",
      "ex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathprocessing\n",
      ".code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorearrows.code.te\n",
      "x)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreshade.code.tex\n",
      ")\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreimage.code.tex\n",
      "\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreexternal.code.\n",
      "tex))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorelayers.code.te\n",
      "x)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoretransparency.c\n",
      "ode.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepatterns.code.\n",
      "tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorerdf.code.tex))\n",
      ")\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/modules/pgfmoduleshapes.code.tex\n",
      ") (/usr/share/texlive/texmf-dist/tex/generic/pgf/modules/pgfmoduleplot.code.tex\n",
      ")\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/compatibility/pgfcomp-version-0-65\n",
      ".sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/compatibility/pgfcomp-version-1-18\n",
      ".sty)) (/usr/share/texlive/texmf-dist/tex/latex/tools/verbatim.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/environ/environ.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/trimspaces/trimspaces.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/etoolbox/etoolbox.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/tcolorbox/tcbbreakable.code.tex\n",
      "Library (tcolorbox): 'tcbbreakable.code.tex' version '4.15'\n",
      ")) (/usr/share/texlive/texmf-dist/tex/latex/parskip/parskip.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/kvoptions.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ltxcmds.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/kvsetkeys.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/infwarerr.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/etexcmds.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ifluatex.sty)))))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/iftex/iftex.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/fontspec/fontspec.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/l3packages/xparse/xparse.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/l3kernel/expl3.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/l3kernel/expl3-code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/l3kernel/l3xdvipdfmx.def)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/fontspec/fontspec-xetex.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/fontenc.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/tuenc.def))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/fontspec/fontspec.cfg)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/caption/caption.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/caption/caption3.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/float/float.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/tools/enumerate.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/geometry/geometry.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ifpdf.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ifvtex.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/ifxetex/ifxetex.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsmath.sty\n",
      "For additional information on amsmath, use the `?' option.\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amstext.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsgen.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsbsy.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsopn.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsfonts/amssymb.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsfonts/amsfonts.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/textcomp.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/ts1enc.def))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/upquote/upquote.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/eurosym/eurosym.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/ucs/ucs.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/ucs/data/uni-global.def))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/fancyvrb/fancyvrb.sty\n",
      "Style option: `fancyvrb' v3.2a <2019/01/15> (tvz))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/grffile.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/pdftexcmds.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/adjustbox.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/xkeyval/xkeyval.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/xkeyval/xkeyval.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/xkeyval/xkvutils.tex)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/adjcalc.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/trimclip.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/collectbox/collectbox.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/tc-xetex.def))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/ifoddpage/ifoddpage.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/varwidth/varwidth.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/hyperref.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/hobsub-hyperref.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/hobsub-generic.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/auxhook.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/pd1enc.def)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/latexconfig/hyperref.cfg)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/url/url.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/hxetex.def\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/puenc.def)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/stringenc.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/rerunfilecheck.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/titling/titling.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/tools/longtable.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/booktabs/booktabs.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/enumitem/enumitem.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/ulem/ulem.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/jknapltx/mathrsfs.sty)\n",
      "No file notebook.aux.\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/ts1cmr.fd)\n",
      "ABD: EveryShipout initializing macros\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/caption/ltcaption.sty)\n",
      "*geometry* driver: auto-detecting\n",
      "*geometry* detected driver: xetex\n",
      "*geometry* verbose mode - [ preamble ] result:\n",
      "* driver: xetex\n",
      "* paper: <default>\n",
      "* layout: <same size as paper>\n",
      "* layoutoffset:(h,v)=(0.0pt,0.0pt)\n",
      "* modes: \n",
      "* h-part:(L,W,R)=(72.26999pt, 469.75502pt, 72.26999pt)\n",
      "* v-part:(T,H,B)=(72.26999pt, 650.43001pt, 72.26999pt)\n",
      "* \\paperwidth=614.295pt\n",
      "* \\paperheight=794.96999pt\n",
      "* \\textwidth=469.75502pt\n",
      "* \\textheight=650.43001pt\n",
      "* \\oddsidemargin=0.0pt\n",
      "* \\evensidemargin=0.0pt\n",
      "* \\topmargin=-37.0pt\n",
      "* \\headheight=12.0pt\n",
      "* \\headsep=25.0pt\n",
      "* \\topskip=11.0pt\n",
      "* \\footskip=30.0pt\n",
      "* \\marginparwidth=59.0pt\n",
      "* \\marginparsep=10.0pt\n",
      "* \\columnsep=10.0pt\n",
      "* \\skip\\footins=10.0pt plus 4.0pt minus 2.0pt\n",
      "* \\hoffset=0.0pt\n",
      "* \\voffset=0.0pt\n",
      "* \\mag=1000\n",
      "* \\@twocolumnfalse\n",
      "* \\@twosidefalse\n",
      "* \\@mparswitchfalse\n",
      "* \\@reversemarginfalse\n",
      "* (1in=72.27pt=25.4mm, 1cm=28.453pt)\n",
      "\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/ucs/ucsencs.def)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/nameref.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/gettitlestring.sty))\n",
      "\n",
      "Package hyperref Warning: Rerun to get /PageLabels entry.\n",
      "\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsfonts/umsa.fd)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsfonts/umsb.fd)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/jknapltx/ursfs.fd)\n",
      "\n",
      "LaTeX Warning: No \\author given.\n",
      "\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/se-ascii-print.def)\n",
      "\n",
      "LaTeX Warning: File `attachment:27d67016-1a87-45ec-acc8-cf6a498607c6.png' not f\n",
      "ound on input line 398.\n",
      "\n",
      "! Unable to load picture or PDF file 'attachment:27d67016-1a87-45ec-acc8-cf6a49\n",
      "8607c6.png'.\n",
      "<to be read again> \n",
      "                   }\n",
      "l.398 ...27d67016-1a87-45ec-acc8-cf6a498607c6.png}\n",
      "                                                  \n",
      "? \n",
      "! Emergency stop.\n",
      "<to be read again> \n",
      "                   }\n",
      "l.398 ...27d67016-1a87-45ec-acc8-cf6a498607c6.png}\n",
      "                                                  \n",
      "No pages of output.\n",
      "Transcript written on notebook.log.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/jupyter-nbconvert\", line 11, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/jupyter_core/application.py\", line 254, in launch_instance\n",
      "    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/nbconvert/nbconvertapp.py\", line 350, in start\n",
      "    self.convert_notebooks()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/nbconvert/nbconvertapp.py\", line 524, in convert_notebooks\n",
      "    self.convert_single_notebook(notebook_filename)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/nbconvert/nbconvertapp.py\", line 489, in convert_single_notebook\n",
      "    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/nbconvert/nbconvertapp.py\", line 418, in export_single_notebook\n",
      "    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/nbconvert/exporters/exporter.py\", line 181, in from_filename\n",
      "    return self.from_file(f, resources=resources, **kw)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/nbconvert/exporters/exporter.py\", line 199, in from_file\n",
      "    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/nbconvert/exporters/pdf.py\", line 183, in from_notebook_node\n",
      "    self.run_latex(tex_file)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/nbconvert/exporters/pdf.py\", line 154, in run_latex\n",
      "    self.latex_count, log_error, raise_on_failure)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/nbconvert/exporters/pdf.py\", line 143, in run_command\n",
      "    command=command, output=out))\n",
      "nbconvert.exporters.pdf.LatexFailed: PDF creating failed, captured latex output:\n",
      "Failed to run \"['xelatex', 'notebook.tex', '-quiet']\" command:\n",
      "This is XeTeX, Version 3.14159265-2.6-0.99999 (TeX Live 2019/dev/Debian) (preloaded format=xelatex)\n",
      " restricted \\write18 enabled.\n",
      "entering extended mode\n",
      "(./notebook.tex\n",
      "LaTeX2e <2018-12-01>\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/article.cls\n",
      "Document Class: article 2018/09/03 v1.4i Standard LaTeX document class\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/size11.clo))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/tcolorbox/tcolorbox.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/basiclayer/pgf.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/utilities/pgfrcs.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfutil-common.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfutil-common-lists.t\n",
      "ex)) (/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfutil-latex.def\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/ms/everyshi.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfrcs.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/pgf.revision.tex)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/basiclayer/pgfcore.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics/graphicx.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics/keyval.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics/graphics.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics/trig.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics-cfg/graphics.cfg)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics-def/xetex.def)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/systemlayer/pgfsys.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfkeys.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfkeysfiltered.code.t\n",
      "ex)) (/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgf.cfg)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys-xetex.def\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys-dvipdfmx.def\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys-common-pdf.de\n",
      "f))))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsyssoftpath.code.\n",
      "tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsysprotocol.code.\n",
      "tex)) (/usr/share/texlive/texmf-dist/tex/latex/xcolor/xcolor.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics-cfg/color.cfg))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcore.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmath.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathcalc.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathutil.code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathparser.code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.basic.code\n",
      ".tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.trigonomet\n",
      "ric.code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.random.cod\n",
      "e.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.comparison\n",
      ".code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.base.code.\n",
      "tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.round.code\n",
      ".tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.misc.code.\n",
      "tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.integerari\n",
      "thmetics.code.tex)))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfloat.code.tex))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepoints.code.te\n",
      "x)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathconstruct.\n",
      "code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathusage.code\n",
      ".tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorescopes.code.te\n",
      "x)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoregraphicstate.c\n",
      "ode.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoretransformation\n",
      "s.code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorequick.code.tex\n",
      ")\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreobjects.code.t\n",
      "ex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathprocessing\n",
      ".code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorearrows.code.te\n",
      "x)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreshade.code.tex\n",
      ")\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreimage.code.tex\n",
      "\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreexternal.code.\n",
      "tex))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorelayers.code.te\n",
      "x)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoretransparency.c\n",
      "ode.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepatterns.code.\n",
      "tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorerdf.code.tex))\n",
      ")\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/modules/pgfmoduleshapes.code.tex\n",
      ") (/usr/share/texlive/texmf-dist/tex/generic/pgf/modules/pgfmoduleplot.code.tex\n",
      ")\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/compatibility/pgfcomp-version-0-65\n",
      ".sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/compatibility/pgfcomp-version-1-18\n",
      ".sty)) (/usr/share/texlive/texmf-dist/tex/latex/tools/verbatim.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/environ/environ.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/trimspaces/trimspaces.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/etoolbox/etoolbox.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/tcolorbox/tcbbreakable.code.tex\n",
      "Library (tcolorbox): 'tcbbreakable.code.tex' version '4.15'\n",
      ")) (/usr/share/texlive/texmf-dist/tex/latex/parskip/parskip.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/kvoptions.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ltxcmds.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/kvsetkeys.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/infwarerr.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/etexcmds.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ifluatex.sty)))))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/iftex/iftex.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/fontspec/fontspec.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/l3packages/xparse/xparse.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/l3kernel/expl3.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/l3kernel/expl3-code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/l3kernel/l3xdvipdfmx.def)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/fontspec/fontspec-xetex.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/fontenc.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/tuenc.def))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/fontspec/fontspec.cfg)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/caption/caption.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/caption/caption3.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/float/float.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/tools/enumerate.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/geometry/geometry.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ifpdf.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ifvtex.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/ifxetex/ifxetex.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsmath.sty\n",
      "For additional information on amsmath, use the `?' option.\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amstext.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsgen.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsbsy.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsopn.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsfonts/amssymb.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsfonts/amsfonts.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/textcomp.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/ts1enc.def))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/upquote/upquote.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/eurosym/eurosym.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/ucs/ucs.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/ucs/data/uni-global.def))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/fancyvrb/fancyvrb.sty\n",
      "Style option: `fancyvrb' v3.2a <2019/01/15> (tvz))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/grffile.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/pdftexcmds.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/adjustbox.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/xkeyval/xkeyval.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/xkeyval/xkeyval.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/xkeyval/xkvutils.tex)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/adjcalc.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/trimclip.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/collectbox/collectbox.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/tc-xetex.def))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/ifoddpage/ifoddpage.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/varwidth/varwidth.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/hyperref.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/hobsub-hyperref.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/hobsub-generic.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/auxhook.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/pd1enc.def)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/latexconfig/hyperref.cfg)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/url/url.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/hxetex.def\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/puenc.def)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/stringenc.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/rerunfilecheck.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/titling/titling.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/tools/longtable.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/booktabs/booktabs.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/enumitem/enumitem.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/ulem/ulem.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/jknapltx/mathrsfs.sty)\n",
      "No file notebook.aux.\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/ts1cmr.fd)\n",
      "ABD: EveryShipout initializing macros\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/caption/ltcaption.sty)\n",
      "*geometry* driver: auto-detecting\n",
      "*geometry* detected driver: xetex\n",
      "*geometry* verbose mode - [ preamble ] result:\n",
      "* driver: xetex\n",
      "* paper: <default>\n",
      "* layout: <same size as paper>\n",
      "* layoutoffset:(h,v)=(0.0pt,0.0pt)\n",
      "* modes: \n",
      "* h-part:(L,W,R)=(72.26999pt, 469.75502pt, 72.26999pt)\n",
      "* v-part:(T,H,B)=(72.26999pt, 650.43001pt, 72.26999pt)\n",
      "* \\paperwidth=614.295pt\n",
      "* \\paperheight=794.96999pt\n",
      "* \\textwidth=469.75502pt\n",
      "* \\textheight=650.43001pt\n",
      "* \\oddsidemargin=0.0pt\n",
      "* \\evensidemargin=0.0pt\n",
      "* \\topmargin=-37.0pt\n",
      "* \\headheight=12.0pt\n",
      "* \\headsep=25.0pt\n",
      "* \\topskip=11.0pt\n",
      "* \\footskip=30.0pt\n",
      "* \\marginparwidth=59.0pt\n",
      "* \\marginparsep=10.0pt\n",
      "* \\columnsep=10.0pt\n",
      "* \\skip\\footins=10.0pt plus 4.0pt minus 2.0pt\n",
      "* \\hoffset=0.0pt\n",
      "* \\voffset=0.0pt\n",
      "* \\mag=1000\n",
      "* \\@twocolumnfalse\n",
      "* \\@twosidefalse\n",
      "* \\@mparswitchfalse\n",
      "* \\@reversemarginfalse\n",
      "* (1in=72.27pt=25.4mm, 1cm=28.453pt)\n",
      "\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/ucs/ucsencs.def)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/nameref.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/gettitlestring.sty))\n",
      "\n",
      "Package hyperref Warning: Rerun to get /PageLabels entry.\n",
      "\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsfonts/umsa.fd)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsfonts/umsb.fd)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/jknapltx/ursfs.fd)\n",
      "\n",
      "LaTeX Warning: No \\author given.\n",
      "\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/se-ascii-print.def)\n",
      "\n",
      "LaTeX Warning: File `attachment:27d67016-1a87-45ec-acc8-cf6a498607c6.png' not f\n",
      "ound on input line 398.\n",
      "\n",
      "! Unable to load picture or PDF file 'attachment:27d67016-1a87-45ec-acc8-cf6a49\n",
      "8607c6.png'.\n",
      "<to be read again> \n",
      "                   }\n",
      "l.398 ...27d67016-1a87-45ec-acc8-cf6a498607c6.png}\n",
      "                                                  \n",
      "? \n",
      "! Emergency stop.\n",
      "<to be read again> \n",
      "                   }\n",
      "l.398 ...27d67016-1a87-45ec-acc8-cf6a498607c6.png}\n",
      "                                                  \n",
      "No pages of output.\n",
      "Transcript written on notebook.log.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save notebook as PDF document\n",
    "!jupyter nbconvert --to pdf `pwd`/*.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110",
   "language": "python",
   "name": "ds5110"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
