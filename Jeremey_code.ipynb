{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 5110 Group Project\n",
    "Team: Alexandra Cathcart (adc6fs), Benjamin Feciura (bmf3bw), Jeremey Donovan (jdd5dw), Jordan Hiatt (jdh2e)\n",
    "\n",
    "Original data: https://www.kaggle.com/reddit/reddit-comments-may-2015\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Includes & Spark Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.tuning import CrossValidator, CrossValidatorModel, ParamGridBuilder\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, countDistinct, lower, size, split, udf, when\n",
    "from pyspark.sql.types import ArrayType, IntegerType,  StringType, StructType\n",
    "\n",
    "#from pyspark import SparkContext\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the reddit data\n",
    "full_path = '/project/ds5559/r-slash-group8/sample.csv'\n",
    "\n",
    "df = spark.read.csv(full_path,  inferSchema=True, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Bad Word data\n",
    "schema = StructType().add(\"badWord\",StringType(),True)\n",
    "dfBW=spark.read.format(\"csv\").schema(schema).load('bad_words.csv')\n",
    "#  dfBW.show(5)  # not showing since words are quite vulgar\n",
    "\n",
    "# Also create in list format\n",
    "listBW=list(dfBW.select('badWord').toPandas()['badWord']) \n",
    "# listBW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regex with all the bad words\n",
    "# if there is an issue, try \\\\\\\\b instead; just \\b probably has issues\n",
    "listBW=list(map(lambda line: \"\\\\b\" + line + \"\\\\b\",listBW))\n",
    "delim='|'\n",
    "strBW=delim.join(listBW)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ups: integer (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- removal_reason: string (nullable = true)\n",
      " |-- downs: integer (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- distinguished: string (nullable = true)\n",
      "\n",
      "+----+---------+--------------+-----+------------+--------------------+-------------+\n",
      "| ups|subreddit|removal_reason|downs|      author|                body|distinguished|\n",
      "+----+---------+--------------+-----+------------+--------------------+-------------+\n",
      "|   4|soccer_jp|            NA|    0|       rx109|                くそ|         null|\n",
      "|null|     null|          null| null|        null|                null|         null|\n",
      "|   0|     null|          null| null|        null|                null|         null|\n",
      "|   4|      nba|            NA|    0|   WyaOfWade|gg this one's ove...|           NA|\n",
      "|   0| politics|            NA|    0|Wicked_Truth|Are you really im...|           NA|\n",
      "+----+---------+--------------+-----+------------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop unneeded cols from dataframe\n",
    "df=df.drop('_c0','created_utc','subreddit_id','link_id','name','score_hidden','author_flair_css_class', 'gilded', \\\n",
    "        'author_flair_text','id','archived','retrieved_on', 'edited','controversiality','parent_id','score')\n",
    "\n",
    "# convert integer cols (ups, downs, and gilded) to integers\n",
    "# Note: we could have done this by defining a schema before the csv read\n",
    "df=df.withColumn(\"ups\",df.ups.cast(IntegerType()))\n",
    "df=df.withColumn(\"downs\",df.downs.cast(IntegerType()))\n",
    "#df=df.withColumn(\"gilded\",df.gilded.cast(IntegerType()))  # Removed gilded since not used in this analysis\n",
    "\n",
    "# Confirm new schema\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15317725"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of rows before removing NA\n",
    "df.count()\n",
    "# There are 15,317,725 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------+-----+--------------+--------------------+-------------+\n",
      "|ups|subreddit|removal_reason|downs|        author|                body|distinguished|\n",
      "+---+---------+--------------+-----+--------------+--------------------+-------------+\n",
      "|  4|soccer_jp|            NA|    0|         rx109|                くそ|         null|\n",
      "|  4|      nba|            NA|    0|     WyaOfWade|gg this one's ove...|           NA|\n",
      "|  0| politics|            NA|    0|  Wicked_Truth|Are you really im...|           NA|\n",
      "|  3|AskReddit|            NA|    0|      jesse9o3|No one has a Euro...|           NA|\n",
      "|  3|AskReddit|            NA|    0|beltfedshooter|\"That the kid \"\"....|           NA|\n",
      "+---+---------+--------------+-----+--------------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove rows where up, down, or body is null. We  do this since inference of these values is not applicable\n",
    "df=df.filter(df['ups'].isNotNull())\n",
    "df=df.filter(df['downs'].isNotNull())\n",
    "df=df.filter(df['body'].isNotNull())\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where the author was '[deleted]' \n",
    "df=df.filter(df['author']!='[deleted]')\n",
    "\n",
    "# Remove author \"0\"\n",
    "df=df.filter(df['author']!='0')\n",
    "\n",
    "\n",
    "# Remove rows where the author was 'AutoModerator'\n",
    "# see https://www.reddit.com/wiki/automoderator\n",
    "df=df.filter(df['author']!='AutoModerator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9226090"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of rows AFTER removing NA\n",
    "df.count()\n",
    "# There now 9,226,090 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all body text\n",
    "df=df.withColumn('body',lower(col('body')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------+-----+--------------+--------------------+-------------+-----+\n",
      "|ups|subreddit|removal_reason|downs|        author|                body|distinguished|score|\n",
      "+---+---------+--------------+-----+--------------+--------------------+-------------+-----+\n",
      "|  4|soccer_jp|            NA|    0|         rx109|                くそ|         null|    4|\n",
      "|  4|      nba|            NA|    0|     WyaOfWade|gg this one's ove...|           NA|    4|\n",
      "|  0| politics|            NA|    0|  Wicked_Truth|are you really im...|           NA|    0|\n",
      "|  3|AskReddit|            NA|    0|      jesse9o3|no one has a euro...|           NA|    3|\n",
      "|  3|AskReddit|            NA|    0|beltfedshooter|\"that the kid \"\"....|           NA|    3|\n",
      "+---+---------+--------------+-----+--------------+--------------------+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Even though we dropped the column, adding score back into dataframe by computing it\n",
    "df=df.withColumn('score',df['ups']-df['downs'])\n",
    "df=df.withColumn(\"score\",df.score.cast(IntegerType()))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------+-----+---------+--------------------+-------------+-----+--------------+\n",
      "|ups|subreddit|removal_reason|downs|   author|                body|distinguished|score|scoreSentiment|\n",
      "+---+---------+--------------+-----+---------+--------------------+-------------+-----+--------------+\n",
      "|  4|soccer_jp|            NA|    0|    rx109|                くそ|         null|    4|           2.0|\n",
      "|  4|      nba|            NA|    0|WyaOfWade|gg this one's ove...|           NA|    4|           2.0|\n",
      "+---+---------+--------------+-----+---------+--------------------+-------------+-----+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Determine a scoreSentiment as either postive, neutral, or negative.\n",
    "# This will be our response variable\n",
    "\n",
    "# Drop scoreSentiment if it already exists\n",
    "df=df.drop('scoreSentiment')\n",
    "\n",
    "# Set up bucketizer\n",
    "splits = [-float(\"inf\"), -0.1,0.1, float(\"inf\")]\n",
    "bkt = Bucketizer(splits=splits, inputCol=\"score\", outputCol=\"scoreSentiment\")\n",
    "\n",
    "# Transform to add scoreSentiment: 0=negative; 1=neutral; 2=positive.\n",
    "df=bkt.transform(df)\n",
    "\n",
    "# !!! Cannot shift to -1,0,1 since LR must start with 0 !!!\n",
    "# To make things more clear, shift to -1=negative; 0=neutral; 1=positive\n",
    "#df=df.withColumn(\"scoreSentiment\", \\\n",
    "#                 when(df['scoreSentiment']==0,-1) \\\n",
    "#                 .when(df['scoreSentiment']==1,0) \\\n",
    "#                 .otherwise(1)\n",
    "#                ) \n",
    "\n",
    "df.show(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag comments containing bad words\n",
    "df=df.withColumn('bwFlag',col('body').rlike(strBW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append bodyWordCount\n",
    "df=df.withColumn(\"bodyWordCount\", size(split(df['body'], ' ')))\n",
    "#df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Though not the cleanest thing to do from a data sci perspective, we\n",
    "# are going to drop the neutral sentiment rows so we can do binomial\n",
    "# rather than multinomial regression; neutral currently \"1\"\n",
    "df=df.filter(df['scoreSentiment']!=1)\n",
    "# Shift positive from 2 to 1\n",
    "df=df.withColumn(\"scoreSentiment\", \\\n",
    "                 when(df['scoreSentiment']==2,1) \\\n",
    "                 .when(df['scoreSentiment']==0,0) \\\n",
    "                 .otherwise(-1)\n",
    "                ) \n",
    "# we should never have the otherwise case!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validator explicity wants response to be called \"label\"\n",
    "# so copying scoreSentiment to label in all DFs\n",
    "df=df.withColumn(\"label\", df[\"scoreSentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting & Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=314\n",
    "trainDF,testDF=df.randomSplit([0.8,0.2],seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|bwFlag|count(bwFlag)|\n",
      "+------+-------------+\n",
      "|  true|       392771|\n",
      "| false|      8433257|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many comments have bad words?\n",
    "# Confirm the flagging worked by looking at how many comments contain bad words vs good\n",
    "# NOTE: This has a rather long runtime!!!\n",
    "df.groupby('bwFlag').agg({\"bwFlag\":\"count\"}).show()\n",
    "#df.filter(df['bwFlag']==True).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|count(DISTINCT author)|\n",
      "+----------------------+\n",
      "|               1216598|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many authors are there?\n",
    "df.select(countDistinct('author')).show()\n",
    "# There are 1,216,598 authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------+-------------+--------+\n",
      "|             author|sum(score)|sum(downs)|count(author)|sum(ups)|\n",
      "+-------------------+----------+----------+-------------+--------+\n",
      "|      TheNitromeFan|     10445|         0|         3997|   10445|\n",
      "|        TweetPoster|      7090|         0|         3589|    7090|\n",
      "|        autowikibot|      6420|         0|         3210|    6420|\n",
      "|         PoliticBot|      3159|         0|         3142|    3159|\n",
      "|TweetsInCommentsBot|      9965|         0|         3130|    9965|\n",
      "|     atomicimploder|      7363|         0|         2616|    7363|\n",
      "|       Removedpixel|      5333|         0|         2265|    5333|\n",
      "|          TrollaBot|      2640|         0|         2247|    2640|\n",
      "|          havoc_bot|      2120|         0|         2102|    2120|\n",
      "|     MTGCardFetcher|      3089|         0|         2084|    3089|\n",
      "+-------------------+----------+----------+-------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the top 10 authors with sum of ups and downs\n",
    "df.groupby('author').agg({\"author\":\"count\",\"ups\":\"sum\",\"downs\":\"sum\",\"score\":\"sum\"}).sort(col('count(author)').desc()).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Odd that the preceding authors have no down but this is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+----------+--------+\n",
      "|          author|sum(score)|sum(downs)|sum(ups)|\n",
      "+----------------+----------+----------+--------+\n",
      "|    ItWillBeMine|     -6839|         0|   -6839|\n",
      "|        blaghart|     -4233|         0|   -4233|\n",
      "|       Shanondoa|     -3555|         0|   -3555|\n",
      "|   bad_driverman|     -3053|         0|   -3053|\n",
      "|      RSneedsEoC|     -2192|         0|   -2192|\n",
      "|   b00gymonster1|     -2050|         0|   -2050|\n",
      "|      frankenham|     -2024|         0|   -2024|\n",
      "|   SaddharKadham|     -1485|         0|   -1485|\n",
      "|letters_numbers-|     -1412|         0|   -1412|\n",
      "|     djroomba322|     -1392|         0|   -1392|\n",
      "+----------------+----------+----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show authors with the lowest scores\n",
    "df.groupby('author').agg({\"score\":\"sum\",\"ups\":\"sum\",\"downs\":\"sum\"}).sort(col('sum(score)').asc()).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------------+\n",
      "|scoreSentiment|count(scoreSentiment)|\n",
      "+--------------+---------------------+\n",
      "|           0.0|               394008|\n",
      "|           1.0|               400062|\n",
      "|           2.0|              8432020|\n",
      "+--------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get a summary of score sentiment by label\n",
    "#tmpDF.groupby('scoreSentiment').agg({\"scoreSentiment\":\"count\"}).show()\n",
    "df.groupby('scoreSentiment').agg({\"scoreSentiment\":\"count\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graphical Distribution of sentiment (TBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Predict Sentiment from body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               words|                  tf|\n",
      "+--------------------+--------------------+\n",
      "|              [くそ]|(262144,[85691],[...|\n",
      "|[gg, this, one's,...|(262144,[5674,905...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create TF (Term Frequency) feature\n",
    "tok = Tokenizer(inputCol=\"body\", outputCol=\"words\")\n",
    "htf = HashingTF(inputCol=\"words\", outputCol=\"tf\")  # numFeatures will be a hyper-parameter  \n",
    "\n",
    "#testing\n",
    "tmpDF=tok.transform(df)\n",
    "tmpDF=htf.transform(tmpDF)\n",
    "tmpDF.select('words','tf').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------+-----+---------+--------------------+-------------+-----+--------------+------+-------------+-----+--------------------+--------------------+\n",
      "|ups|subreddit|removal_reason|downs|   author|                body|distinguished|score|scoreSentiment|bwFlag|bodyWordCount|label|             bodyVec|                 w2v|\n",
      "+---+---------+--------------+-----+---------+--------------------+-------------+-----+--------------+------+-------------+-----+--------------------+--------------------+\n",
      "|  4|soccer_jp|            NA|    0|    rx109|                くそ|         null|    4|             1| false|            1|    1|              [くそ]|[0.0,0.0,0.0,0.0,...|\n",
      "|  4|      nba|            NA|    0|WyaOfWade|gg this one's ove...|           NA|    4|             1| false|           12|    1|[gg this one's ov...|[0.0,0.0,0.0,0.0,...|\n",
      "+---+---------+--------------+-----+---------+--------------------+-------------+-----+--------------+------+-------------+-----+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create w2v (word to vec) feature\n",
    "\n",
    "# the comment string needs to be turned into a vector for w2v to work\n",
    "# unfortunately, VectorAssember does not work on string so we need a UDF\n",
    "\n",
    "# Create UDF (note: split(anything,0) simply means don't split)\n",
    "str_to_vec=spark.udf.register(\"str_to_vec\",\n",
    "                             lambda row:row.split(\"#\",0),\n",
    "                             ArrayType(StringType()))\n",
    "\n",
    "# set up the tranformation\n",
    "rva=SQLTransformer(statement=\"SELECT *, str_to_vec(body) bodyVec FROM __THIS__\")\n",
    "\n",
    "w2v = Word2Vec(inputCol='bodyVec', outputCol='w2v')  # not setting minCount \n",
    "\n",
    "# testing\n",
    "tmpDF=rva.transform(df)\n",
    "model=w2v.fit(tmpDF)\n",
    "tmpDF=model.transform(tmpDF)\n",
    "tmpDF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble predictors\n",
    "va=VectorAssembler(inputCols=['tf','w2v','bwFlag','bodyWordCount'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the regression model; regParam & elasticNetParam will be hyper-parameters\n",
    "# CrossVal currently requires the labelCol to be precisely called 'label'\n",
    "#lr = LogisticRegression(labelCol='scoreSentiment',maxIter=10)\n",
    "lr = LogisticRegression(labelCol='label',maxIter=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the pipeline\n",
    "#pipeline=Pipeline(stages=[bkt,tok,htf,rva,w2v,va,lr])  # took out bkt since this is pre-EDA\n",
    "pipeline=Pipeline(stages=[tok,htf,rva,w2v,va,lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up hyperparameter tuning & Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nparamGrid = ParamGridBuilder()     .addGrid(htf.numFeatures, [200])     .addGrid(lr.regParam, [0.3])     .addGrid(lr.elasticNetParam, [0.5])     .build()\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the parameter grid\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(htf.numFeatures, [100, 1000]) \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "\n",
    "# This paramGrid for testing\n",
    "\"\"\"\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(htf.numFeatures, [200]) \\\n",
    "    .addGrid(lr.regParam, [0.3]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.5]) \\\n",
    "    .build()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint('-'*30)\\n#print('paramGrid', paramGrid, '\\n')\\n#print('len(paramGrid): {}'.format(len(paramGrid)))\\nprint('-'*30)\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Too inspect paramGrid, uncomment next 4 lines\n",
    "\"\"\"\n",
    "print('-'*30)\n",
    "#print('paramGrid', paramGrid, '\\n')\n",
    "#print('len(paramGrid): {}'.format(len(paramGrid)))\n",
    "print('-'*30)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "# Using the pipeline as the estimator slows things down but is necessary if tuning featurziers.  If not, set the \n",
    "# model specification as the estimator with estimator=lr (I think; though not sure if that means lr needs to be removed from pipeline)\n",
    "numFolds=5\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(labelCol='label'),\n",
    "                          numFolds=numFolds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine parallelism \n",
    "# This resource: see https://databricks.com/session/model-parallelism-in-spark-ml-cross-validation\n",
    "# says that best practice is parallelism = (# cores)/(# partitions) but generally not more than 10\n",
    "numPartitions=trainDF.rdd.getNumPartitions()\n",
    "numCores=sc.defaultParallelism\n",
    "parallelism=int(round(numCores/numPartitions,0))\n",
    "# also see https://stackoverflow.com/questions/42171499/get-current-number-of-partitions-of-a-dataframe\n",
    "\n",
    "# constrain to between 1 and 10\n",
    "if parallelism<1:\n",
    "    parallelism=1\n",
    "elif parallelism > 10:\n",
    "    parallelism=10\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "    \n",
    "\"\"\"\n",
    "# Another thing we can do is treat cores as fixed and repartition to get a target parallelism\n",
    "# while avoiding memory issues that occur when != cores/partitions\n",
    "# in the future: verify cores/partitions is correct; might want to do something to avoid having\n",
    "# too few partitions\n",
    "parallelism=2\n",
    "targetNumPartitions=int(round(numCores/parallelism,0))\n",
    "if (targetNumPartitions>=1):\n",
    "    if (targetNumPartitions<numPartitions):\n",
    "        trainDF = trainDF.coalesce(targetNumPartitions) # no shuffling but can only be used for decreasing numPartitions\n",
    "    else: \n",
    "        trainDF = trainDF.repartition(targetNumPartitions)  # this involves shuffling to less efficient\n",
    "\"\"\" \n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# However, elsewhere, you typically see that partitions should be 2x to 4x the number of cores!\n",
    "# So, we could just override (note: 4 yielded memory errors)\n",
    "parallelism=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out parallelism\n",
    "parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache trainDF to speed up cross validation; we could use .select(colnames...) to use less memory\n",
    "# Cache & persist failed with 32GB of memory\n",
    "#trainDF=trainDF.cache()\n",
    "#trainDF=trainDF.persist(StorageLevel.MEMORY_AND_DISK_ONLY)\n",
    "#trainDF.count()  # call count to actually cache the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "import time\n",
    "t0 = time.time()\n",
    "if parallelism==1:\n",
    "    cvModel = crossval.fit(trainDF) # train models (no parallelism)\n",
    "else:    \n",
    "    cvModel = crossval.setParallelism(parallelism).fit(trainDF) # train models in parallel\n",
    "print(\"train time:\", time.time() - t0)\n",
    "print('-'*30)\n",
    "# Took 3580 secs (~1hr) to run single params set with 5 fold on 8 cores with 32 GB memmory & no parallelism & no cache/persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release the cache\n",
    "#trainDF.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "cvModel.save(\"spark-log-reg-model\")\n",
    "pipeline.save(\"spark-log-reg-pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and the pipeline  (should these be preceded by \"val\")\n",
    "crossValidatorModel = CrossValidatorModel.load(\"spark-log-reg-model\")\n",
    "#sameModel = PipelineModel.load(\"/path-to-my-pipeline/spark-log-reg-transfer-pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE ONLY OK ABOVE THIS POINT !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the multinomial logistic regression model; this is old - before implemementing cross validation\n",
    "mlrModel=pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      "3 X 300 CSRMatrix\n",
      "\n",
      "Intercept: [-1.0264586714522934,-1.0107704204551655,2.037229091907459]\n",
      "objectiveHistory:\n",
      "0.35298803317465105\n",
      "False positive rate by label:\n",
      "label 0: 0.0\n",
      "label 1: 0.0\n",
      "label 2: 1.0\n",
      "True positive rate by label:\n",
      "label 0: 0.0\n",
      "label 1: 0.0\n",
      "label 2: 1.0\n",
      "Precision by label:\n",
      "label 0: 0.0\n",
      "label 1: 0.0\n",
      "label 2: 0.9139359489937812\n",
      "Recall by label:\n",
      "label 0: 0.0\n",
      "label 1: 0.0\n",
      "label 2: 1.0\n",
      "F-measure by label:\n",
      "label 0: 0.0\n",
      "label 1: 0.0\n",
      "label 2: 0.9550329513109017\n",
      "Accuracy: 0.9139359489937812\n",
      "FPR: 0.9139359489937812\n",
      "TPR: 0.9139359489937812\n",
      "F-measure: 0.8728389466766606\n",
      "Precision: 0.8352789188631633\n",
      "Recall: 0.9139359489937812\n"
     ]
    }
   ],
   "source": [
    "# Training Summary\n",
    "# source: https://spark.apache.org/docs/latest/ml-classification-regression.html\n",
    "\n",
    "# Fix source: https://stackoverflow.com/questions/37278999/logistic-regression-with-spark-ml-data-frames\n",
    "lrm=mlrModel.stages[-1]\n",
    "\n",
    "# Print the coefficients and intercept for multinomial logistic regression\n",
    "print(\"Coefficients: \\n\" + str(lrm.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(lrm.interceptVector))\n",
    "\n",
    "trainingSummary = lrm.summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# for multiclass, we can inspect metrics on a per-label basis\n",
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make preductions on the test data\n",
    "mlrPrediction=mlrModel.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+\n",
      "|scoreSentiment|prediction|\n",
      "+--------------+----------+\n",
      "|           0.0|       2.0|\n",
      "|           0.0|       2.0|\n",
      "|           0.0|       2.0|\n",
      "+--------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlrPrediction.select('scoreSentiment','prediction').show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TBD: Evaluate the predictions. Judging from the training though, it seems to over-predict category 2 \"positive\" --- which is the most prevalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stuff with ngrams not currently used\n",
    "\n",
    "#May need to drop col when rerunning\n",
    "#df=df.drop('body2grams')\n",
    "#df=df.drop('body3grams')\n",
    "\n",
    "# Create 2grams\n",
    "#ngram = NGram(n=2, inputCol=\"words\", outputCol=\"body2grams\")\n",
    "#df = ngram.transform(df)\n",
    "\n",
    "# Create 3grams\n",
    "#ngram = NGram(n=3, inputCol=\"words\", outputCol=\"body3grams\")\n",
    "#df = ngram.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT USED since scoreSentiment is multinomial response not predictor\n",
    "# OneHotEncoding of Score_sentiment\n",
    "# since it is already numeric, no need for StringIndexer\n",
    "#encoder = OneHotEncoder(inputCol=\"score_sentiment\", outputCol=\"scoreSentimentVec\")\n",
    "#model = encoder.fit(df)\n",
    "#df = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save notebook as PDF document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook /sfs/qumulo/qhome/jdd5dw/ds5110-project/Jeremey_code.ipynb to pdf\n",
      "[NbConvertApp] Writing 57104 bytes to notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 68569 bytes to /sfs/qumulo/qhome/jdd5dw/ds5110-project/Jeremey_code.pdf\n",
      "[NbConvertApp] Converting notebook /sfs/qumulo/qhome/jdd5dw/ds5110-project/test_file.ipynb to pdf\n",
      "[NbConvertApp] Writing 26544 bytes to notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
      "[NbConvertApp] CRITICAL | xelatex failed: ['xelatex', 'notebook.tex', '-quiet']\n",
      "This is XeTeX, Version 3.14159265-2.6-0.99999 (TeX Live 2019/dev/Debian) (preloaded format=xelatex)\n",
      " restricted \\write18 enabled.\n",
      "entering extended mode\n",
      "(./notebook.tex\n",
      "LaTeX2e <2018-12-01>\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/article.cls\n",
      "Document Class: article 2018/09/03 v1.4i Standard LaTeX document class\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/size11.clo))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/tcolorbox/tcolorbox.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/basiclayer/pgf.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/utilities/pgfrcs.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfutil-common.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfutil-common-lists.t\n",
      "ex)) (/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfutil-latex.def\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/ms/everyshi.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfrcs.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/pgf.revision.tex)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/basiclayer/pgfcore.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics/graphicx.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics/keyval.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics/graphics.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics/trig.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics-cfg/graphics.cfg)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics-def/xetex.def)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/systemlayer/pgfsys.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfkeys.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfkeysfiltered.code.t\n",
      "ex)) (/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgf.cfg)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys-xetex.def\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys-dvipdfmx.def\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys-common-pdf.de\n",
      "f))))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsyssoftpath.code.\n",
      "tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsysprotocol.code.\n",
      "tex)) (/usr/share/texlive/texmf-dist/tex/latex/xcolor/xcolor.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics-cfg/color.cfg))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcore.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmath.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathcalc.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathutil.code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathparser.code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.basic.code\n",
      ".tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.trigonomet\n",
      "ric.code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.random.cod\n",
      "e.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.comparison\n",
      ".code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.base.code.\n",
      "tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.round.code\n",
      ".tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.misc.code.\n",
      "tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.integerari\n",
      "thmetics.code.tex)))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfloat.code.tex))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepoints.code.te\n",
      "x)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathconstruct.\n",
      "code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathusage.code\n",
      ".tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorescopes.code.te\n",
      "x)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoregraphicstate.c\n",
      "ode.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoretransformation\n",
      "s.code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorequick.code.tex\n",
      ")\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreobjects.code.t\n",
      "ex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathprocessing\n",
      ".code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorearrows.code.te\n",
      "x)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreshade.code.tex\n",
      ")\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreimage.code.tex\n",
      "\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreexternal.code.\n",
      "tex))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorelayers.code.te\n",
      "x)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoretransparency.c\n",
      "ode.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepatterns.code.\n",
      "tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorerdf.code.tex))\n",
      ")\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/modules/pgfmoduleshapes.code.tex\n",
      ") (/usr/share/texlive/texmf-dist/tex/generic/pgf/modules/pgfmoduleplot.code.tex\n",
      ")\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/compatibility/pgfcomp-version-0-65\n",
      ".sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/compatibility/pgfcomp-version-1-18\n",
      ".sty)) (/usr/share/texlive/texmf-dist/tex/latex/tools/verbatim.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/environ/environ.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/trimspaces/trimspaces.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/etoolbox/etoolbox.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/tcolorbox/tcbbreakable.code.tex\n",
      "Library (tcolorbox): 'tcbbreakable.code.tex' version '4.15'\n",
      ")) (/usr/share/texlive/texmf-dist/tex/latex/parskip/parskip.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/kvoptions.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ltxcmds.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/kvsetkeys.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/infwarerr.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/etexcmds.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ifluatex.sty)))))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/iftex/iftex.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/fontspec/fontspec.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/l3packages/xparse/xparse.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/l3kernel/expl3.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/l3kernel/expl3-code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/l3kernel/l3xdvipdfmx.def)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/fontspec/fontspec-xetex.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/fontenc.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/tuenc.def))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/fontspec/fontspec.cfg)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/caption/caption.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/caption/caption3.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/float/float.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/tools/enumerate.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/geometry/geometry.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ifpdf.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ifvtex.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/ifxetex/ifxetex.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsmath.sty\n",
      "For additional information on amsmath, use the `?' option.\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amstext.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsgen.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsbsy.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsopn.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsfonts/amssymb.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsfonts/amsfonts.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/textcomp.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/ts1enc.def))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/upquote/upquote.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/eurosym/eurosym.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/ucs/ucs.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/ucs/data/uni-global.def))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/fancyvrb/fancyvrb.sty\n",
      "Style option: `fancyvrb' v3.2a <2019/01/15> (tvz))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/grffile.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/pdftexcmds.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/adjustbox.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/xkeyval/xkeyval.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/xkeyval/xkeyval.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/xkeyval/xkvutils.tex)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/adjcalc.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/trimclip.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/collectbox/collectbox.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/tc-xetex.def))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/ifoddpage/ifoddpage.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/varwidth/varwidth.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/hyperref.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/hobsub-hyperref.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/hobsub-generic.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/auxhook.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/pd1enc.def)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/latexconfig/hyperref.cfg)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/url/url.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/hxetex.def\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/puenc.def)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/stringenc.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/rerunfilecheck.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/titling/titling.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/tools/longtable.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/booktabs/booktabs.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/enumitem/enumitem.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/ulem/ulem.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/jknapltx/mathrsfs.sty)\n",
      "No file notebook.aux.\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/ts1cmr.fd)\n",
      "ABD: EveryShipout initializing macros\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/caption/ltcaption.sty)\n",
      "*geometry* driver: auto-detecting\n",
      "*geometry* detected driver: xetex\n",
      "*geometry* verbose mode - [ preamble ] result:\n",
      "* driver: xetex\n",
      "* paper: <default>\n",
      "* layout: <same size as paper>\n",
      "* layoutoffset:(h,v)=(0.0pt,0.0pt)\n",
      "* modes: \n",
      "* h-part:(L,W,R)=(72.26999pt, 469.75502pt, 72.26999pt)\n",
      "* v-part:(T,H,B)=(72.26999pt, 650.43001pt, 72.26999pt)\n",
      "* \\paperwidth=614.295pt\n",
      "* \\paperheight=794.96999pt\n",
      "* \\textwidth=469.75502pt\n",
      "* \\textheight=650.43001pt\n",
      "* \\oddsidemargin=0.0pt\n",
      "* \\evensidemargin=0.0pt\n",
      "* \\topmargin=-37.0pt\n",
      "* \\headheight=12.0pt\n",
      "* \\headsep=25.0pt\n",
      "* \\topskip=11.0pt\n",
      "* \\footskip=30.0pt\n",
      "* \\marginparwidth=59.0pt\n",
      "* \\marginparsep=10.0pt\n",
      "* \\columnsep=10.0pt\n",
      "* \\skip\\footins=10.0pt plus 4.0pt minus 2.0pt\n",
      "* \\hoffset=0.0pt\n",
      "* \\voffset=0.0pt\n",
      "* \\mag=1000\n",
      "* \\@twocolumnfalse\n",
      "* \\@twosidefalse\n",
      "* \\@mparswitchfalse\n",
      "* \\@reversemarginfalse\n",
      "* (1in=72.27pt=25.4mm, 1cm=28.453pt)\n",
      "\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/ucs/ucsencs.def)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/nameref.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/gettitlestring.sty))\n",
      "\n",
      "Package hyperref Warning: Rerun to get /PageLabels entry.\n",
      "\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsfonts/umsa.fd)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsfonts/umsb.fd)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/jknapltx/ursfs.fd)\n",
      "\n",
      "LaTeX Warning: No \\author given.\n",
      "\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/se-ascii-print.def)\n",
      "\n",
      "LaTeX Warning: File `attachment:27d67016-1a87-45ec-acc8-cf6a498607c6.png' not f\n",
      "ound on input line 398.\n",
      "\n",
      "! Unable to load picture or PDF file 'attachment:27d67016-1a87-45ec-acc8-cf6a49\n",
      "8607c6.png'.\n",
      "<to be read again> \n",
      "                   }\n",
      "l.398 ...27d67016-1a87-45ec-acc8-cf6a498607c6.png}\n",
      "                                                  \n",
      "? \n",
      "! Emergency stop.\n",
      "<to be read again> \n",
      "                   }\n",
      "l.398 ...27d67016-1a87-45ec-acc8-cf6a498607c6.png}\n",
      "                                                  \n",
      "No pages of output.\n",
      "Transcript written on notebook.log.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/jupyter-nbconvert\", line 11, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/jupyter_core/application.py\", line 254, in launch_instance\n",
      "    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/nbconvert/nbconvertapp.py\", line 350, in start\n",
      "    self.convert_notebooks()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/nbconvert/nbconvertapp.py\", line 524, in convert_notebooks\n",
      "    self.convert_single_notebook(notebook_filename)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/nbconvert/nbconvertapp.py\", line 489, in convert_single_notebook\n",
      "    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/nbconvert/nbconvertapp.py\", line 418, in export_single_notebook\n",
      "    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/nbconvert/exporters/exporter.py\", line 181, in from_filename\n",
      "    return self.from_file(f, resources=resources, **kw)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/nbconvert/exporters/exporter.py\", line 199, in from_file\n",
      "    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/nbconvert/exporters/pdf.py\", line 183, in from_notebook_node\n",
      "    self.run_latex(tex_file)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/nbconvert/exporters/pdf.py\", line 154, in run_latex\n",
      "    self.latex_count, log_error, raise_on_failure)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/nbconvert/exporters/pdf.py\", line 143, in run_command\n",
      "    command=command, output=out))\n",
      "nbconvert.exporters.pdf.LatexFailed: PDF creating failed, captured latex output:\n",
      "Failed to run \"['xelatex', 'notebook.tex', '-quiet']\" command:\n",
      "This is XeTeX, Version 3.14159265-2.6-0.99999 (TeX Live 2019/dev/Debian) (preloaded format=xelatex)\n",
      " restricted \\write18 enabled.\n",
      "entering extended mode\n",
      "(./notebook.tex\n",
      "LaTeX2e <2018-12-01>\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/article.cls\n",
      "Document Class: article 2018/09/03 v1.4i Standard LaTeX document class\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/size11.clo))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/tcolorbox/tcolorbox.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/basiclayer/pgf.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/utilities/pgfrcs.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfutil-common.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfutil-common-lists.t\n",
      "ex)) (/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfutil-latex.def\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/ms/everyshi.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfrcs.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/pgf.revision.tex)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/basiclayer/pgfcore.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics/graphicx.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics/keyval.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics/graphics.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics/trig.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics-cfg/graphics.cfg)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics-def/xetex.def)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/systemlayer/pgfsys.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfkeys.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfkeysfiltered.code.t\n",
      "ex)) (/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgf.cfg)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys-xetex.def\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys-dvipdfmx.def\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys-common-pdf.de\n",
      "f))))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsyssoftpath.code.\n",
      "tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsysprotocol.code.\n",
      "tex)) (/usr/share/texlive/texmf-dist/tex/latex/xcolor/xcolor.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics-cfg/color.cfg))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcore.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmath.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathcalc.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathutil.code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathparser.code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.code.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.basic.code\n",
      ".tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.trigonomet\n",
      "ric.code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.random.cod\n",
      "e.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.comparison\n",
      ".code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.base.code.\n",
      "tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.round.code\n",
      ".tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.misc.code.\n",
      "tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.integerari\n",
      "thmetics.code.tex)))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfloat.code.tex))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepoints.code.te\n",
      "x)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathconstruct.\n",
      "code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathusage.code\n",
      ".tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorescopes.code.te\n",
      "x)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoregraphicstate.c\n",
      "ode.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoretransformation\n",
      "s.code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorequick.code.tex\n",
      ")\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreobjects.code.t\n",
      "ex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathprocessing\n",
      ".code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorearrows.code.te\n",
      "x)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreshade.code.tex\n",
      ")\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreimage.code.tex\n",
      "\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreexternal.code.\n",
      "tex))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorelayers.code.te\n",
      "x)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoretransparency.c\n",
      "ode.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepatterns.code.\n",
      "tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorerdf.code.tex))\n",
      ")\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/pgf/modules/pgfmoduleshapes.code.tex\n",
      ") (/usr/share/texlive/texmf-dist/tex/generic/pgf/modules/pgfmoduleplot.code.tex\n",
      ")\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/compatibility/pgfcomp-version-0-65\n",
      ".sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/pgf/compatibility/pgfcomp-version-1-18\n",
      ".sty)) (/usr/share/texlive/texmf-dist/tex/latex/tools/verbatim.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/environ/environ.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/trimspaces/trimspaces.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/etoolbox/etoolbox.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/tcolorbox/tcbbreakable.code.tex\n",
      "Library (tcolorbox): 'tcbbreakable.code.tex' version '4.15'\n",
      ")) (/usr/share/texlive/texmf-dist/tex/latex/parskip/parskip.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/kvoptions.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ltxcmds.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/kvsetkeys.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/infwarerr.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/etexcmds.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ifluatex.sty)))))\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/iftex/iftex.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/fontspec/fontspec.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/l3packages/xparse/xparse.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/l3kernel/expl3.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/l3kernel/expl3-code.tex)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/l3kernel/l3xdvipdfmx.def)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/fontspec/fontspec-xetex.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/fontenc.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/tuenc.def))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/fontspec/fontspec.cfg)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/caption/caption.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/caption/caption3.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/float/float.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/tools/enumerate.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/geometry/geometry.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ifpdf.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ifvtex.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/ifxetex/ifxetex.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsmath.sty\n",
      "For additional information on amsmath, use the `?' option.\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amstext.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsgen.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsbsy.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsopn.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsfonts/amssymb.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsfonts/amsfonts.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/textcomp.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/ts1enc.def))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/upquote/upquote.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/eurosym/eurosym.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/ucs/ucs.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/ucs/data/uni-global.def))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/fancyvrb/fancyvrb.sty\n",
      "Style option: `fancyvrb' v3.2a <2019/01/15> (tvz))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/grffile.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/pdftexcmds.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/adjustbox.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/xkeyval/xkeyval.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/xkeyval/xkeyval.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/xkeyval/xkvutils.tex)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/adjcalc.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/trimclip.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/collectbox/collectbox.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/tc-xetex.def))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/ifoddpage/ifoddpage.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/varwidth/varwidth.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/hyperref.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/hobsub-hyperref.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/hobsub-generic.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/auxhook.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/pd1enc.def)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/latexconfig/hyperref.cfg)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/url/url.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/hxetex.def\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/puenc.def)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/stringenc.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/rerunfilecheck.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/titling/titling.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/tools/longtable.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/booktabs/booktabs.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/enumitem/enumitem.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/ulem/ulem.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/jknapltx/mathrsfs.sty)\n",
      "No file notebook.aux.\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/ts1cmr.fd)\n",
      "ABD: EveryShipout initializing macros\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/caption/ltcaption.sty)\n",
      "*geometry* driver: auto-detecting\n",
      "*geometry* detected driver: xetex\n",
      "*geometry* verbose mode - [ preamble ] result:\n",
      "* driver: xetex\n",
      "* paper: <default>\n",
      "* layout: <same size as paper>\n",
      "* layoutoffset:(h,v)=(0.0pt,0.0pt)\n",
      "* modes: \n",
      "* h-part:(L,W,R)=(72.26999pt, 469.75502pt, 72.26999pt)\n",
      "* v-part:(T,H,B)=(72.26999pt, 650.43001pt, 72.26999pt)\n",
      "* \\paperwidth=614.295pt\n",
      "* \\paperheight=794.96999pt\n",
      "* \\textwidth=469.75502pt\n",
      "* \\textheight=650.43001pt\n",
      "* \\oddsidemargin=0.0pt\n",
      "* \\evensidemargin=0.0pt\n",
      "* \\topmargin=-37.0pt\n",
      "* \\headheight=12.0pt\n",
      "* \\headsep=25.0pt\n",
      "* \\topskip=11.0pt\n",
      "* \\footskip=30.0pt\n",
      "* \\marginparwidth=59.0pt\n",
      "* \\marginparsep=10.0pt\n",
      "* \\columnsep=10.0pt\n",
      "* \\skip\\footins=10.0pt plus 4.0pt minus 2.0pt\n",
      "* \\hoffset=0.0pt\n",
      "* \\voffset=0.0pt\n",
      "* \\mag=1000\n",
      "* \\@twocolumnfalse\n",
      "* \\@twosidefalse\n",
      "* \\@mparswitchfalse\n",
      "* \\@reversemarginfalse\n",
      "* (1in=72.27pt=25.4mm, 1cm=28.453pt)\n",
      "\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/ucs/ucsencs.def)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/hyperref/nameref.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/gettitlestring.sty))\n",
      "\n",
      "Package hyperref Warning: Rerun to get /PageLabels entry.\n",
      "\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsfonts/umsa.fd)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsfonts/umsb.fd)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/jknapltx/ursfs.fd)\n",
      "\n",
      "LaTeX Warning: No \\author given.\n",
      "\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/se-ascii-print.def)\n",
      "\n",
      "LaTeX Warning: File `attachment:27d67016-1a87-45ec-acc8-cf6a498607c6.png' not f\n",
      "ound on input line 398.\n",
      "\n",
      "! Unable to load picture or PDF file 'attachment:27d67016-1a87-45ec-acc8-cf6a49\n",
      "8607c6.png'.\n",
      "<to be read again> \n",
      "                   }\n",
      "l.398 ...27d67016-1a87-45ec-acc8-cf6a498607c6.png}\n",
      "                                                  \n",
      "? \n",
      "! Emergency stop.\n",
      "<to be read again> \n",
      "                   }\n",
      "l.398 ...27d67016-1a87-45ec-acc8-cf6a498607c6.png}\n",
      "                                                  \n",
      "No pages of output.\n",
      "Transcript written on notebook.log.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save notebook as PDF document\n",
    "!jupyter nbconvert --to pdf `pwd`/*.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110",
   "language": "python",
   "name": "ds5110"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
